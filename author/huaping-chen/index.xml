<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Huaping Chen | USTC-AC</title>
    <link>http://localhost:1313/author/huaping-chen/</link>
      <atom:link href="http://localhost:1313/author/huaping-chen/index.xml" rel="self" type="application/rss+xml" />
    <description>Huaping Chen</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 Jan 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_huc3da470f1a231b6fd15916059be12d5d_66382_512x512_fill_lanczos_center_3.png</url>
      <title>Huaping Chen</title>
      <link>http://localhost:1313/author/huaping-chen/</link>
    </image>
    
    <item>
      <title>Thermal Augmented Expression Recognition</title>
      <link>http://localhost:1313/publication/dblp-journalstcyb-wang-pcj-18/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/dblp-journalstcyb-wang-pcj-18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Facial Expression Recognition with Deep two-view Support Vector Machine</title>
      <link>http://localhost:1313/publication/dblp-confmm-wu-wpc-16/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/dblp-confmm-wu-wpc-16/</guid>
      <description>&lt;p&gt;This paper proposes a novel deep two-view approach to learn features from both visible and thermal images and leverage the commonality among visible and thermal images for facial expression recognition from visible images. The thermal images are used as privileged information, which is required only during training to help visible images learn better features and classifier. Specifically, we first learn a deep model for visible images and thermal images respectively, and use the learned feature representations to train SVM classifiers for expression classification. We then jointly refine the deep models as well as the SVM classifiers for both thermal images and visible images by imposing the constraint that the outputs of the SVM classifiers from two views are similar. Therefore, the resulting representations and classifiers capture the inherent connections among visible facial image, infrared facial image and target expression labels, and hence improve the recognition performance for facial expression recognition from visible images during testing. Experimental results on the benchmark expression database demonstrate the effectiveness of our proposed method.&lt;/p&gt;














&lt;figure  id=&#34;figure-fig-the-scheme-of-deep-network-for-visible-image-data-thermal-image-data-and-the-scheme-of-the-proposed-model&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. The scheme of deep network for visible image data, thermal image data and the scheme of the proposed model.&#34; srcset=&#34;
               /publication/dblp-confmm-wu-wpc-16/featured_hu4a007d55c83268e1c22352006fcba45d_180260_0ecaa368acedc411a8d4fff2952e216b.JPG 400w,
               /publication/dblp-confmm-wu-wpc-16/featured_hu4a007d55c83268e1c22352006fcba45d_180260_d620d56d8d33e7b0a84c6ddf224ae0a5.JPG 760w,
               /publication/dblp-confmm-wu-wpc-16/featured_hu4a007d55c83268e1c22352006fcba45d_180260_1200x1200_fit_q75_lanczos.JPG 1200w&#34;
               src=&#34;http://localhost:1313/publication/dblp-confmm-wu-wpc-16/featured_hu4a007d55c83268e1c22352006fcba45d_180260_0ecaa368acedc411a8d4fff2952e216b.JPG&#34;
               width=&#34;760&#34;
               height=&#34;328&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. The scheme of deep network for visible image data, thermal image data and the scheme of the proposed model.
    &lt;/figcaption&gt;&lt;/figure&gt;
</description>
    </item>
    
  </channel>
</rss>
