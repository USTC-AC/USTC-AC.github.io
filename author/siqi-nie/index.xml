<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Siqi Nie | USTC-AC</title>
    <link>http://localhost:1313/author/siqi-nie/</link>
      <atom:link href="http://localhost:1313/author/siqi-nie/index.xml" rel="self" type="application/rss+xml" />
    <description>Siqi Nie</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_huc3da470f1a231b6fd15916059be12d5d_66382_512x512_fill_lanczos_center_3.png</url>
      <title>Siqi Nie</title>
      <link>http://localhost:1313/author/siqi-nie/</link>
    </image>
    
    <item>
      <title>Differentiating Between Posed and Spontaneous Expressions with Latent Regression Bayesian Network</title>
      <link>http://localhost:1313/publication/dblp-confaaai-gan-nwj-17/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/dblp-confaaai-gan-nwj-17/</guid>
      <description>&lt;p&gt;Spatial patterns embedded in human faces are crucial for differentiating posed expressions from spontaneous ones, yet they have not been thoroughly exploited in the literature. To tackle this problem, we present a generative model, i.e., Latent Regression Bayesian Network (LRBN), to effectively capture the spatial patterns embedded in facial landmark points to differentiate between posed and spontaneous facial expressions. The LRBN is a directed graphical model consisting of one latent layer and one visible layer. Due to the “explaining away” effect in Bayesian networks, LRBN is able to capture both the dependencies among the latent variables given the observation and the dependencies among visible variables. We believe that such dependencies are crucial for faithful data representation. Specifically, during training, we construct two LRBNs to capture spatial patterns inherent in displacements of landmark points from spontaneous facial expressions and posed facial expressions respectively. During testing, the samples are classified into posed or spontaneous expressions according to their likelihoods on two models. Efficient learning and inference algorithms are proposed. Experimental results on two benchmark databases demonstrate the advantages of the proposed approach in modeling spatial patterns as well as its superior performance to the existing methods in differentiating between posed and spontaneous expressions.&lt;/p&gt;














&lt;figure  id=&#34;figure-fig-the-framework-of-capturing-spatial-patterns&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig. The framework of capturing spatial patterns&#34; srcset=&#34;
               /publication/dblp-confaaai-gan-nwj-17/featured_hu5eafe8c2628672eb14e0c65744466ffa_86294_efc2b202e0496b643e7469c436369d59.jpg 400w,
               /publication/dblp-confaaai-gan-nwj-17/featured_hu5eafe8c2628672eb14e0c65744466ffa_86294_b9cbd7521ce6355a25d7e9d9350ea896.jpg 760w,
               /publication/dblp-confaaai-gan-nwj-17/featured_hu5eafe8c2628672eb14e0c65744466ffa_86294_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;http://localhost:1313/publication/dblp-confaaai-gan-nwj-17/featured_hu5eafe8c2628672eb14e0c65744466ffa_86294_efc2b202e0496b643e7469c436369d59.jpg&#34;
               width=&#34;760&#34;
               height=&#34;377&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig. The framework of capturing spatial patterns
    &lt;/figcaption&gt;&lt;/figure&gt;
</description>
    </item>
    
  </channel>
</rss>
